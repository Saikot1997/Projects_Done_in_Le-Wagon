{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5myCg3voCYMR"
      },
      "source": [
        "# MNIST Classification"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "A6Wl03m4CYMU"
      },
      "source": [
        "üéØ <b><u>Exercise objectives</u></b>\n",
        "- Understand the *MNIST* dataset \n",
        "- Design your first **Convolutional Neural Network** (*CNN*) and answer questions such as:\n",
        "    - what are *Convolutional Layers*? \n",
        "    - how many *parameters* are involved in such a layer?\n",
        "- Train this CNN on images"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tYFY1oi2CYMV"
      },
      "source": [
        "üöÄ <b><u>Let's get started!</u></b>\n",
        "\n",
        "Imagine that we are  back in time into the 90's.\n",
        "You work at a *Post Office* and you have to deal with an enormous amount of letters on a daily basis. How could you automate the process of reading the ZIP Codes, which are a combination of 5 handwritten digits? \n",
        "\n",
        "This task, called the **Handwriting Recognition**, used to be a very complex problem back in those days. It was solved by *Bell Labs* (among others) where one of the Deep Learning gurus, [*Yann Le Cun*](https://en.wikipedia.org/wiki/Yann_LeCun), used to work.\n",
        "\n",
        "From [Wikipedia](https://en.wikipedia.org/wiki/Handwriting_recognition):\n",
        "\n",
        "> Handwriting recognition (HWR), also known as Handwritten Text Recognition (HTR), is the ability of a computer to receive and interpret intelligible handwritten input from sources such as paper documents, photographs, touch-screens and other devices"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "d2XFAga9CYMV"
      },
      "source": [
        "![Number recognition](recognition.gif)\n",
        "\n",
        "*Note: The animation above is just here to help you visualize what happens with the different images: <br/> $\\rightarrow$ For each image, once the CNN is trained, it will predict what digit is written. The inputs are the different digits and not one animation/video!*"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5epxFf7hCYMW"
      },
      "source": [
        "ü§î <b><u>How does this CNN work ?</u></b>\n",
        "\n",
        "- *Inputs*: Images (_each image shows a handwritten digit_)\n",
        "- *Target*: For each image, you want your CNN model to predict the correct digit (between 0 and 9)\n",
        "    - It is a **multi-class classification** task (more precisely a 10-class classification task since there are 10 different digits).\n",
        "\n",
        "üî¢ To improve the capacity of the Convolutional Neural Network to read these numbers, we need to feed it with many images representing handwritten digits. This is why the üìö [**MNIST dataset**](http://yann.lecun.com/exdb/mnist/) *(Mixed National Institute of Standards and Technology)* was created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HZDrVmvDCYMW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7NTv2I1mCYMX"
      },
      "source": [
        "## (1) The `MNIST` Dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LECOTHZaCYMX"
      },
      "source": [
        "üìö Tensorflow/Keras offers multiple [**datasets**](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) to play with:\n",
        "- *Vectors*: `boston_housing` (regression)\n",
        "- *Images* : `mnist`, `fashion_mnist`, `cifar10`, `cifar100` (classification)\n",
        "- *Texts*: `imbd`, `reuters` (classification/sentiment analysis)\n",
        "\n",
        "\n",
        "üíæ You can **load the MNIST dataset** with the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F58rUGoPCYMY",
        "outputId": "c834cd2a-f886-4f10-9dcb-ef99c6933766"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(((60000, 28, 28), (60000,)), ((10000, 28, 28), (10000,)))"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras import datasets\n",
        "\n",
        "\n",
        "# Loading the MNIST Dataset...\n",
        "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data(path=\"mnist.npz\")\n",
        "\n",
        "# The train set contains 60 000 images, each of them of size 28x28\n",
        "# The test set contains 10 000 images, each of them of size 28x28\n",
        "(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "J5NEOCOhCYMY"
      },
      "source": [
        "### (1.1) Exploring the dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-JzQYc8uCYMY"
      },
      "source": [
        "‚ùì **Question: Let's have look at some handwritten digits of this MNIST dataset.** ‚ùì\n",
        "\n",
        "üñ® Print some images from the *train set*.\n",
        "\n",
        "<details>\n",
        "    <summary><i>Hints</i></summary>\n",
        "\n",
        "üí°*Hint*: use the `imshow` function from `matplotlib` with `cmap = \"gray\"`\n",
        "\n",
        "ü§® Note: if you don't specify this *cmap* argument, the weirdly displayed colors are just Matplotlib defaults...\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "RkSLw0v2CYMY",
        "outputId": "7ea51970-a08f-46f3-d8bb-6a3cb74955e6",
        "tags": [
          "challengify"
        ]
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i+1)\n",
        "    plt.imshow(X_train[i], cmap=\"gray\")\n",
        "    plt.title(f\"Label: {y_train[i]}\")\n",
        "    plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mGQOpNZxCYMY"
      },
      "source": [
        "### (1.2) Image Preprocessing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zdHt6OgMCYMZ"
      },
      "source": [
        "‚ùóÔ∏è **Neural Networks converge faster when the input data is somehow normalized** ‚ùóÔ∏è\n",
        "\n",
        "üë©üèª‚Äçüè´ How do we proceed for Convolutional Neural Networks ?\n",
        "* The `RBG` intensities are coded between 0 and 255. \n",
        "* We can simply divide the input data by the maximal value 255 to have all the pixels' intensities between 0 and 1 üòâ"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "I0Nw6qyYCYMZ"
      },
      "source": [
        "‚ùì **Question ‚ùì As a first preprocessing step, please normalize your data.** \n",
        "\n",
        "Don't forget to do it both on your train data and your test data.\n",
        "\n",
        "(*Note: you can also center your data, by subtracting 0.5 from all the values, but it is not mandatory*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ph5zKzCwCYMZ",
        "tags": [
          "challengify"
        ]
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "import numpy as np\n",
        "\n",
        "X_train_normalized = X_train / 255.0\n",
        "X_test_normalized = X_test / 255.0\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PGhOq69nCYMZ"
      },
      "source": [
        "### (1.3) Inputs' dimensionality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iejJd4kECYMZ",
        "outputId": "d29236c8-b497-46fc-f1d5-757b5b90de4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DwTQpNNbCYMZ"
      },
      "source": [
        "üëÜ Remember that you have 60,000 training images and 10,000 test images, each of size $(28, 28)$. However...\n",
        "\n",
        "> ‚ùóÔ∏è  **`Convolutional Neural Network models need to be fed with images whose last dimension is the number of channels`.**  \n",
        "\n",
        "> üßëüèª‚Äçüè´ The shape of tensors fed into ***ConvNets*** is the following: `(NUMBER_OF_IMAGES, HEIGHT, WIDTH, CHANNELS)`\n",
        "\n",
        "üïµüèªThis last dimension is clearly missing here. Can you guess the reason why?\n",
        "<br>\n",
        "<details>\n",
        "    <summary><i>Answer<i></summary>\n",
        "        \n",
        "* All these $60000$ $ (28 \\times 28) $ pictures are black-and-white $ \\implies $ Each pixel lives on a spectrum from full black (0) to full white (1).\n",
        "        \n",
        "    * Theoretically, you don't need to know the number of channels for a black-and-white picture since there is only 1 channel (the \"whiteness\" of \"blackness\" of a pixel). However, it is still mandatory for the model to have this number of channels explicitly stated.\n",
        "        \n",
        "    * In comparison, colored pictures need multiple channels:\n",
        "        - the RGB system with 3 channels (<b><span style=\"color:red\">Red</span> <span style=\"color:green\">Green</span> <span style=\"color:blue\">Blue</span></b>)\n",
        "        - the CYMK system  with 4 channels (<b><span style=\"color:cyan\">Cyan</span> <span style=\"color:magenta\">Magenta</span> <span style=\"color:yellow\">Yellow</span> <span style=\"color:black\">Black</span></b>)\n",
        "        \n",
        "        \n",
        "</details>        "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zeSkAuvZCYMZ"
      },
      "source": [
        "‚ùì **Question: expanding dimensions** ‚ùì\n",
        "\n",
        "* Use the **`expand_dims`** to add one dimension at the end of the training data and test data.\n",
        "\n",
        "* Then, print the shapes of `X_train` and `X_test`. They should respectively be equal to $(60000, 28, 28, 1)$ and $(10000, 28, 28, 1)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "aB-4XWurCYMa"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.backend import expand_dims"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ii2U3yB_CYMa",
        "outputId": "e5bae116-3643-4787-ada2-ad7e73ef26c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "X_train_expanded = np.expand_dims(X_train_normalized, axis=-1)\n",
        "X_test_expanded = np.expand_dims(X_test_normalized, axis=-1)\n",
        "\n",
        "print(X_train_expanded.shape)\n",
        "print(X_test_expanded.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zHMNizYdCYMa"
      },
      "source": [
        "### (1.4) Target encoding"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fdJoYuH1CYMa"
      },
      "source": [
        "One more thing to for a multiclass classification task in Deep Leaning:\n",
        "\n",
        "üëâ _\"one-hot-encode\" the categories*_\n",
        "\n",
        "‚ùì **Question: encoding the labels** ‚ùì \n",
        "\n",
        "* Use **`to_categorical`** to transform your labels. \n",
        "* Store the results into two variables that you can call **`y_train_cat`** and **`y_test_cat`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_2Hq7bTfCYMa"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hpuN35oUCYMa"
      },
      "outputs": [],
      "source": [
        "# Quick check that you correctly used to_categorical\n",
        "assert(y_train_cat.shape == (60000,10))\n",
        "assert(y_test_cat.shape == (10000,10))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4_duRwM9CYMb"
      },
      "source": [
        "The data is now ready to be used. ‚úÖ"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2UHFz-lECYMb"
      },
      "source": [
        "## (2) The Convolutional Neural Network"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iKXkqX2BCYMb"
      },
      "source": [
        "### (2.1) Architecture and compilation of a CNN"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KXJEoGPOCYMb"
      },
      "source": [
        "\n",
        "‚ùì **Question: CNN Architecture and compilation** ‚ùì\n",
        "\n",
        "Now, let's build a <u>Convolutional Neural Network</u> that has: \n",
        "\n",
        "\n",
        "- a `Conv2D` layer with 8 filters, each of size $(4, 4)$, an input shape suitable for your task, the `relu` activation function, and `padding='same'`\n",
        "- a `MaxPool2D` layer with a `pool_size` equal to $(2, 2)$\n",
        "- a second `Conv2D` layer with 16 filters, each of size $(3, 3)$, and the `relu` activation function\n",
        "- a second `MaxPool2D` layer with a `pool_size` equal to $(2, 2)$\n",
        "\n",
        "\n",
        "- a `Flatten` layer\n",
        "- a first `Dense` layer with 10 neurons and the `relu` activation function\n",
        "- a last (predictive) layer that is suited for your task\n",
        "\n",
        "In the function that initializes this model, do not forget to include the <u>compilation of the model</u>, which:\n",
        "* optimizes the `categorical_crossentropy` loss function,\n",
        "* with the `adam` optimizer, \n",
        "* and the `accuracy` as the metrics\n",
        "\n",
        "(*Note: you could add more classification metrics if you want but the dataset is well balanced!*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ykuGR0mrG7SD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-24 11:58:29.545940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-05-24 11:58:29.549682: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2023-05-24 11:58:29.549865: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
            "2023-05-24 11:58:29.549991: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "2023-05-24 11:58:29.550145: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
            "2023-05-24 11:58:29.550196: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
            "2023-05-24 11:58:29.550284: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
            "2023-05-24 11:58:29.550333: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
            "2023-05-24 11:58:29.550404: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
            "2023-05-24 11:58:29.550414: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2023-05-24 11:58:29.551258: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "def initialize_model():\n",
        "    model = models.Sequential()\n",
        "\n",
        "    ### First Convolution & MaxPooling\n",
        "    model.add(layers.Conv2D(8, (4, 4), activation='relu', padding='same', input_shape=(28, 28, 1)))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "    ### Second Convolution & MaxPooling\n",
        "    model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "    ### Flattening\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    ### One Fully Connected layer\n",
        "    model.add(layers.Dense(10, activation='relu'))\n",
        "\n",
        "    ### Last layer - Classification Layer\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    ### Model compilation\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = initialize_model()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ojR9VsmlCYMb"
      },
      "source": [
        "‚ùì **Question: number of trainable parameters in a convolutional layer** ‚ùì \n",
        "\n",
        "How many trainable parameters are there in your model?\n",
        "1. Compute them with ***model.summary( )*** first\n",
        "2. Recompute them manually to make sure you properly understood ***what influences the number of weights in a CNN***."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFZq_YzACYMb",
        "outputId": "ced47e8c-0529-4423-ee6f-56fab45bb3fd",
        "tags": [
          "challengify"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 8)         136       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 8)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 12, 12, 16)        1168      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 576)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                5770      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,184\n",
            "Trainable params: 7,184\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9wER2iXjCYMc"
      },
      "source": [
        "### (2.2) Training a CNN"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ3R0Zg3CYMc"
      },
      "source": [
        "‚ùì **Question: training a CNN** ‚ùì \n",
        "\n",
        "Initialize your model and fit it on the train data. \n",
        "- Do not forget to use a **Validation Set/Split** and an **Early Stopping criterion**. \n",
        "- Limit yourself to 5 epochs max in this challenge, just to save some precious time for the more advanced challenges!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNOfmRx6CYMc",
        "outputId": "480d7868-d110-4673-896b-cfc615f019c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.3070 - accuracy: 0.9042 - val_loss: 0.0935 - val_accuracy: 0.9718\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0985 - accuracy: 0.9700 - val_loss: 0.0760 - val_accuracy: 0.9749\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0747 - accuracy: 0.9775 - val_loss: 0.0529 - val_accuracy: 0.9830\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0606 - accuracy: 0.9818 - val_loss: 0.0605 - val_accuracy: 0.9815\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0523 - accuracy: 0.9836 - val_loss: 0.0470 - val_accuracy: 0.9850\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Initialize the model\n",
        "model = initialize_model()\n",
        "\n",
        "early_stopping = EarlyStopping(patience=3, monitor='val_loss', restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_expanded, y_train_cat,\n",
        "    validation_split=0.3,\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping],\n",
        "    validation_data=(X_test_expanded, y_test_cat)\n",
        ")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "E4TOXUd_CYMc"
      },
      "source": [
        "‚ùì **Question: How many iterations does the CNN perform per epoch** ‚ùì\n",
        "\n",
        "_Note: it has nothing to do with the fact that this is a CNN. This is related to the concept of forward/backward propagation already covered during the previous lecture on optimizers, fitting, and losses üòâ_"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "q2tCEp6SCYMc",
        "tags": [
          "challengify"
        ]
      },
      "source": [
        "The CNN performs 1313 iterations per epoch in this case"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8TFeq8LjCYMc"
      },
      "source": [
        "<details>\n",
        "    <summary><i>Answer</i></summary>\n",
        "\n",
        "With `verbose = 1` when fitting your model, you have access to crucial information about your training procedure.\n",
        "    \n",
        "Remember that we've just trained our CNN model on $60000$ training images\n",
        "\n",
        "If the chosen batch size is 32: \n",
        "\n",
        "* For each epoch, we have $ \\large \\lceil \\frac{60000}{32} \\rceil = 1875$ minibatches <br/>\n",
        "* The _validation_split_ is equal to $0.3$ - which means that within one single epoch, there are:\n",
        "    * $ \\lceil 1875 \\times (1 - 0.3) \\rceil = \\lceil 1312.5 \\rceil = 1313$ batches are used to compute the `train_loss` \n",
        "    * $ 1875 - 1312 = 562 $ batches are used to compute the `val_loss`\n",
        "    * **The parameters are updated 1313 times per epoch** as there are 1313 forward/backward propagations per epoch !!!\n",
        "\n",
        "\n",
        "üëâ With so many updates of the weights within one epoch, you can understand why this CNN model converges even with a limited number of epochs.\n",
        "\n",
        "</details>    \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rd4qqfFACYMq"
      },
      "source": [
        "### (2.3) Evaluating its performance"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pn2MaBp-CYMq"
      },
      "source": [
        "‚ùì **Question: Evaluating your CNN** ‚ùì \n",
        "\n",
        "What is your **`accuracy on the test set?`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qo88DDB5CYMq",
        "outputId": "d15fc2eb-6e13-4a6a-ebbc-243f1fe9b26b",
        "tags": [
          "challengify"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0470 - accuracy: 0.9850\n",
            "Accuracy on the test set: 0.9850000143051147\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "loss , test_accuracy = model.evaluate(X_test_expanded, y_test_cat)\n",
        "print(\"Accuracy on the test set:\", test_accuracy)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vrli8_PcCYMq"
      },
      "source": [
        "üéâ You should already be impressed by your CNN skills! Reaching over 95% accuracy!\n",
        "\n",
        "üî• You solved what was a very hard problem 30 years ago with your own CNN."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "k56nAiNXCYMq"
      },
      "source": [
        "üèÅ **Congratulations!**\n",
        "\n",
        "üíæ Don't forget to `git add/commit/push` your notebook...\n",
        "\n",
        "üöÄ ... and move on to the next challenge!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
